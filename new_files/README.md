# Remote Sensing Change Detection ‚Äì ML Challenge

## üéØ Objectif

Classifier une zone g√©ographique (polygone) en **6 classes** √† partir de features issues d‚Äôimages satellites multi-dates.

**Classes :**

```
0 ‚Äì Demolition
1 ‚Äì Road
2 ‚Äì Residential
3 ‚Äì Commercial
4 ‚Äì Industrial
5 ‚Äì Mega Projects

```

---

## üì¶ Donn√©es

Chaque √©chantillon contient :

- **Un polygone irr√©gulier** (g√©om√©trie)
- **5 statuts cat√©goriels temporels** (√©volution du site)
- **Features urbaines de voisinage** (cat√©gorielles, multi-valeurs)
- **Features g√©ographiques de voisinage** (cat√©gorielles, multi-valeurs)

Les donn√©es sont d√©j√† extraites (pas d‚Äôimages brutes).

---

## üîÅ Pipeline ML (attendu)

1. **Pr√©traitement**
  - Encodage des variables cat√©gorielles (one-hot / ordinal / binaire)
  - Gestion des NaN / inf
  - Normalisation si n√©cessaire
2. **Feature engineering**
  - Polygones ‚Üí `area`, `perimeter`, `compactness`, etc.
  - Statuts temporels ‚Üí
    - dernier statut
    - transitions
    - dur√©e entre changements
  - Urban / Geo features ‚Üí multi-hot encoding
3. **R√©duction / s√©lection de features**
  - PCA / SVD (si utile)
  - Feature selection (variance, mutual info, mod√®les lin√©aires)
4. **Mod√©lisation**
  - Baseline : k-NN (~40%)
  - Mod√®les test√©s / envisag√©s :
    - Logistic Regression
    - SVM (lin√©aire / RBF)
    - Random Forest / Gradient Boosting
    - Naive Bayes (Bernoulli / Multinomial)
    - Ensembles
5. **√âvaluation**
  - Classification **multi-classe**
  - M√©trique principale : **F1-score**
  - Cross-validation
  - Attention au d√©s√©quilibre de classes

---

## üß™ Contraintes connues

- Beaucoup de features cat√©gorielles (one-hot)
- Haute dimension possible
- Bruit + redondance
- Donn√©es g√©ographiques parfois instables (NaN apr√®s projection)

---

## üöÄ Pipeline fourni (objectif F1 ‚â• 95 %)

**Script principal :** `train_and_predict.py`

- **Features :**
  - G√©om√©trie : area, perimeter, compactness, log(area), log(perimeter)
  - Multi-hot : `urban_type`, `geography_type`
  - Statuts : s√©quence encod√©e (5 dates) + nb transitions + **ordre s√©mantique** (max_gap, last_state one-hot, flags de r√©gression) ‚Äî voir `features_extra.py`
  - Image : 30 canaux (RGB mean/std √ó 5 dates) + 12 stats temporelles (moyenne/std dans le temps)
  - Dates en ordinal
- **Pr√©traitement :** m√©diane (train) pour NaN, `StandardScaler`, inf/nan ‚Üí 0.
- **Mod√®le :** Ensemble RF + HistGradientBoosting + ExtraTrees + XGBoost (si install√©). Poids de classe plafonn√©s. Moyenne des probas pour la pr√©diction.
- **Sortie :** `submission.csv` (colonnes `Id`, `change_type` 0‚Äì5).

**Lancer :**
```bash
pip install -r requirements.txt
python train_and_predict.py
```
- Premi√®re run : construction des features + cache dans `feature_cache_v2/` (long).
- Runs suivants : chargement du cache (plus rapide).
- **Pour monter le score (75% ‚Üí 80%+)** : garder `USE_STATUS_EXTRA = False` et les poids de classe plafonn√©s (d√©j√† activ√©s). Avec `SUBSAMPLE = None` (tout le train), viser ~85%+ F1 (run long).
- **Run rapide** : `SUBSAMPLE = 0.2` ou `0.25` ‚Üí ~77% F1 en quelques min.
- **Viser 95 % en CV sur le train** : `SUBSAMPLE = None`, lancer `python train_and_predict.py`. Le script affiche **Ensemble CV F1 weighted** apr√®s la 2-fold CV et l‚Äô√©crit dans `cv_result.txt`. Run complet (donn√©es enti√®res + gros mod√®les) : compter 1‚Äì2 h selon la machine. Pour viser 95 %, installer XGBoost/LightGBM et les int√©grer √† l‚Äôensemble peut aider.

**Entra√Ænement depuis le cache uniquement :**
```bash
python train_from_cache.py   # apr√®s au moins une run compl√®te de train_and_predict.py
```

**Ton code (√©valuation) :** ta CV en k folds et F1 macro est coh√©rente ; ici on utilise une CV stratifi√©e et F1 weighted pour coller √† la m√©trique du README. Les features (ordre des statuts, max_gap, r√©gressions, last_state one-hot) sont int√©gr√©es dans `features_extra.py` et utilis√©es dans le pipeline.

