{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# import and load data set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\pyogrio\\raw.py:200: RuntimeWarning: driver GeoJSON does not support open option INDEX_COL\n",
      "  return ogr_read(\n",
      "C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\pyogrio\\raw.py:200: RuntimeWarning: driver GeoJSON does not support open option INDEX_COL\n",
      "  return ogr_read(\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "change_type_map = {'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,\n",
    "       'Mega Projects': 5}\n",
    "\n",
    "## Read csvs\n",
    "\n",
    "train_df = gpd.read_file('train.geojson', index_col=0)\n",
    "test_df = gpd.read_file('test.geojson', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-02T19:24:12.268608400Z",
     "start_time": "2026-02-02T19:23:30.035158800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\shapely\\measurement.py:50: RuntimeWarning: invalid value encountered in area\n",
      "  return lib.area(geometry, **kwargs)\n",
      "C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\shapely\\measurement.py:196: RuntimeWarning: invalid value encountered in length\n",
      "  return lib.length(geometry, **kwargs)\n",
      "C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\shapely\\measurement.py:50: RuntimeWarning: invalid value encountered in area\n",
      "  return lib.area(geometry, **kwargs)\n",
      "C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\shapely\\measurement.py:196: RuntimeWarning: invalid value encountered in length\n",
      "  return lib.length(geometry, **kwargs)\n",
      "C:\\Users\\Ely Cheikh Abass\\AppData\\Local\\Temp\\ipykernel_7620\\123306701.py:55: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  dates = out[date_cols].apply(pd.to_datetime, errors=\"coerce\", utc=True)\n",
      "C:\\Users\\Ely Cheikh Abass\\AppData\\Local\\Temp\\ipykernel_7620\\123306701.py:55: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  dates = out[date_cols].apply(pd.to_datetime, errors=\"coerce\", utc=True)\n",
      "C:\\Users\\Ely Cheikh Abass\\AppData\\Local\\Temp\\ipykernel_7620\\123306701.py:55: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  dates = out[date_cols].apply(pd.to_datetime, errors=\"coerce\", utc=True)\n",
      "C:\\Users\\Ely Cheikh Abass\\AppData\\Local\\Temp\\ipykernel_7620\\123306701.py:55: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  dates = out[date_cols].apply(pd.to_datetime, errors=\"coerce\", utc=True)\n"
     ]
    }
   ],
   "source": [
    "## Filtering column \"mail_type\"\n",
    "## Adding total construction time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "PRE_CONSTRUCTION_STATUSES = {\n",
    "    \"Greenland\",\n",
    "    \"Land Cleared\",\n",
    "    \"Prior Construction\",\n",
    "    \"Excavation\",\n",
    "    \"Materials Dumped\",\n",
    "    \"Materials Introduced\",\n",
    "    \"Construction Started\",\n",
    "}\n",
    "\n",
    "POST_CONSTRUCTION_STATUSES = {\n",
    "    \"Construction Midway\",\n",
    "    \"Construction Done\",\n",
    "    \"Operational\",\n",
    "}\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def add_geometry_features(gdf, metric_epsg=6933):\n",
    "    \"\"\"\n",
    "    gdf: GeoDataFrame en EPSG:4326\n",
    "    Ajoute:\n",
    "      - polygon_area_m2\n",
    "      - polygon_perimeter_m\n",
    "      - compactness (sans unité)\n",
    "    \"\"\"\n",
    "    # 1) reprojection en CRS métrique (mètres)\n",
    "    gdf_m = gdf.to_crs(epsg=metric_epsg)\n",
    "\n",
    "    # 2) calculs géométriques en mètres\n",
    "    gdf = gdf.copy()\n",
    "    gdf[\"polygon_area_m2\"] = gdf_m.geometry.area\n",
    "    gdf[\"polygon_perimeter_m\"] = gdf_m.geometry.length\n",
    "\n",
    "    # 3) compacité = 4πA / P²\n",
    "    gdf[\"compactness\"] = (\n",
    "        4 * np.pi * gdf[\"polygon_area_m2\"] / (gdf[\"polygon_perimeter_m\"] ** 2)\n",
    "    )\n",
    "    gdf.loc[gdf[\"polygon_perimeter_m\"] == 0, \"compactness\"] = np.nan\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def add_max_gap_between_sets(\n",
    "    df,\n",
    "    date_cols,     # ex: [\"date0\", ..., \"date4\"]\n",
    "    status_cols    # ex: [\"change_status_date0\", ..., \"change_status_date4\"]\n",
    "):\n",
    "    out = df.copy()\n",
    "\n",
    "    dates = out[date_cols].apply(pd.to_datetime, errors=\"coerce\", utc=True)\n",
    "    statuses = out[status_cols]\n",
    "\n",
    "    def row_max_gap(row_dates, row_statuses):\n",
    "        set1_dates = []\n",
    "        set2_dates = []\n",
    "\n",
    "        for d, s in zip(row_dates, row_statuses):\n",
    "            if pd.isna(d) or pd.isna(s):\n",
    "                continue\n",
    "            if s in PRE_CONSTRUCTION_STATUSES:\n",
    "                set1_dates.append(d)\n",
    "            elif s in POST_CONSTRUCTION_STATUSES:\n",
    "                set2_dates.append(d)\n",
    "\n",
    "        if not set1_dates or not set2_dates:\n",
    "            return 0.0\n",
    "\n",
    "        # max |t2 - t1|\n",
    "        max_gap = max(\n",
    "            abs((t2 - t1).total_seconds())\n",
    "            for t1 in set1_dates\n",
    "            for t2 in set2_dates\n",
    "        )\n",
    "\n",
    "        return max_gap / 86400.0  # en jours\n",
    "\n",
    "    out[\"pre_post_construction_time_gap_days\"] = [\n",
    "        row_max_gap(d, s)\n",
    "        for d, s in zip(dates.to_numpy(), statuses.to_numpy())\n",
    "    ]\n",
    "\n",
    "    return out\n",
    "\n",
    "date_cols = [f\"date{i}\" for i in range(5)]\n",
    "status_cols = [f\"change_status_date{i}\" for i in range(5)]\n",
    "\n",
    "train_df = add_geometry_features(train_df)\n",
    "test_df = add_geometry_features(test_df)\n",
    "\n",
    "\n",
    "train_df = add_max_gap_between_sets(train_df, date_cols, status_cols)\n",
    "test_df  = add_max_gap_between_sets(test_df, date_cols, status_cols)\n",
    "\n",
    "#\n",
    "# date_cols = [f'date{i}' for i in range(5)]\n",
    "# status_cols = [f'change_status_date{i}' for i in range(5)]\n",
    "#\n",
    "# def get_const_time(df):\n",
    "#     dt_cols = []\n",
    "#     for i, c in enumerate(date_cols):\n",
    "#         dtc = f\"dt_{i}\"\n",
    "#         df[dtc] = pd.to_datetime(df[c], errors=\"coerce\", utc=True)  # utc pour être stable\n",
    "#         dt_cols.append(dtc)\n",
    "#\n",
    "#     for i, c in enumerate(status_cols):\n",
    "#         df[f\"change_status_date{i}\"].apply(lambda x: status_cols[x])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-02T21:24:51.123123Z",
     "start_time": "2026-02-02T21:24:44.179421500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "\n",
    "# train_x_d = np.asarray(train_df['date0'])\n",
    "feature_cols = [\n",
    "    \"pre_post_construction_time_gap_days\",\n",
    "    \"polygon_area_m2\",\n",
    "    \"polygon_perimeter_m\",\n",
    "    \"compactness\",\n",
    "]\n",
    "\n",
    "# X (numpy arrays)\n",
    "train_x = train_df[feature_cols].to_numpy(dtype=float)\n",
    "test_x  = test_df[feature_cols].to_numpy(dtype=float)\n",
    "\n",
    "# y (labels encodés)\n",
    "train_y = train_df[\"change_type\"].map(change_type_map).to_numpy()\n",
    "\n",
    "print(train_x.shape, train_y.shape, test_x.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# =========================\n",
    "# PARAMÈTRES\n",
    "# =========================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# pipeline FIXE : Imputer -> Scaler -> SVC\n",
    "svc_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),  # gère NaN\n",
    "    (\"scaler\", StandardScaler()),                   # SVC a besoin de scaling\n",
    "    (\"model\", SVC(kernel=\"rbf\", C=1))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# FEATURES AVANT (baseline)\n",
    "# =========================\n",
    "baseline_features = [\n",
    "    \"polygon_area_m2\"   # <-- mets EXACTEMENT ce que tu utilisais avant\n",
    "]\n",
    "\n",
    "X_old = train_df[baseline_features].to_numpy(dtype=float)\n",
    "y = train_df[\"change_type\"].map(change_type_map).to_numpy()\n",
    "\n",
    "scores_old = cross_val_score(\n",
    "    svc_pipe, X_old, y,\n",
    "    cv=cv, scoring=\"f1_macro\", n_jobs=-1\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# FEATURES APRÈS (nouvelles)\n",
    "# =========================\n",
    "new_features = [\n",
    "    \"pre_post_construction_time_gap_days\",\n",
    "    \"polygon_area_m2\",\n",
    "    \"polygon_perimeter_m\",\n",
    "    \"compactness\",\n",
    "]\n",
    "\n",
    "X_new = train_df[new_features].to_numpy(dtype=float)\n",
    "\n",
    "scores_new = cross_val_score(\n",
    "    svc_pipe, X_new, y,\n",
    "    cv=cv, scoring=\"f1_macro\", n_jobs=-1\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# RÉSULTATS\n",
    "# =========================\n",
    "print(\"===== AVANT =====\")\n",
    "print(\"F1 macro mean :\", scores_old.mean())\n",
    "print(\"F1 macro std  :\", scores_old.std())\n",
    "\n",
    "print(\"\\n===== APRÈS =====\")\n",
    "print(\"F1 macro mean :\", scores_new.mean())\n",
    "print(\"F1 macro std  :\", scores_new.std())\n",
    "\n",
    "print(\"\\n===== GAIN =====\")\n",
    "print(\"Gain absolu :\", scores_new.mean() - scores_old.mean())\n",
    "print(\"Gain relatif (%) :\", (scores_new.mean() / scores_old.mean() - 1) * 100)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2026-02-02T21:35:28.034552400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "0.1134029891816655 {'model': SVC(), 'model__C': 1, 'model__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"model\", LogisticRegression())\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        \"model\": [LogisticRegression(max_iter=1000)],\n",
    "        \"model__C\": [0.1, 1, 10]\n",
    "    },\n",
    "    {\n",
    "        \"model\": [SVC()],\n",
    "        \"model__C\": [0.1, 1],\n",
    "        \"model__kernel\": [\"rbf\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": [RandomForestClassifier()],\n",
    "        \"model__n_estimators\": [100, 300]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "grid.fit(train_x, train_y)\n",
    "print(grid.best_score_, grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-02T13:41:35.008895900Z",
     "start_time": "2026-02-02T11:06:56.034178100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict and create csv prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [296146, 120526]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m pred_y \u001B[38;5;241m=\u001B[39m grid\u001B[38;5;241m.\u001B[39mpredict(test_x)\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43maccuracy_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_y\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;250;43m \u001B[39;49m\u001B[43mpred_y\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    214\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    215\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    216\u001B[0m         )\n\u001B[0;32m    217\u001B[0m     ):\n\u001B[1;32m--> 218\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    220\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    221\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    222\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    223\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    224\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    225\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    226\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    227\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    228\u001B[0m     )\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:411\u001B[0m, in \u001B[0;36maccuracy_score\u001B[1;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[0;32m    409\u001B[0m \u001B[38;5;66;03m# Compute accuracy for each possible representation\u001B[39;00m\n\u001B[0;32m    410\u001B[0m y_true, y_pred \u001B[38;5;241m=\u001B[39m attach_unique(y_true, y_pred)\n\u001B[1;32m--> 411\u001B[0m y_type, y_true, y_pred, sample_weight \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    412\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\n\u001B[0;32m    413\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    416\u001B[0m     differing_labels \u001B[38;5;241m=\u001B[39m _count_nonzero(y_true \u001B[38;5;241m-\u001B[39m y_pred, xp\u001B[38;5;241m=\u001B[39mxp, device\u001B[38;5;241m=\u001B[39mdevice, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:108\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred, sample_weight)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001B[39;00m\n\u001B[0;32m     78\u001B[0m \n\u001B[0;32m     79\u001B[0m \u001B[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;124;03msample_weight : array or None\u001B[39;00m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    107\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(y_true, y_pred, sample_weight)\n\u001B[1;32m--> 108\u001B[0m \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    109\u001B[0m type_true \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    110\u001B[0m type_pred \u001B[38;5;241m=\u001B[39m type_of_target(y_pred, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:464\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    462\u001B[0m lengths \u001B[38;5;241m=\u001B[39m [_num_samples(X) \u001B[38;5;28;01mfor\u001B[39;00m X \u001B[38;5;129;01min\u001B[39;00m arrays \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[0;32m    463\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mset\u001B[39m(lengths)) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 464\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    465\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    466\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[0;32m    467\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [296146, 120526]"
     ]
    }
   ],
   "source": [
    "pred_y = grid.predict(test_x)\n",
    "print(f\"{accuracy_score(train_y, pred_y)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-02T19:21:36.633793300Z",
     "start_time": "2026-02-02T19:01:59.452916300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "## Save results to submission file\n",
    "pred_df = pd.DataFrame(pred_y, columns=['change_type'])\n",
    "pred_df.to_csv(\"knn_sample_submission.csv\", index=True, index_label='Id')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": ".venv",
   "language": "python",
   "display_name": "Python (.venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
