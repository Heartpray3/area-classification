{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# import and load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-03T10:38:42.843023900Z",
     "start_time": "2026-02-03T10:38:01.251879700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\pyogrio\\raw.py:200: RuntimeWarning: driver GeoJSON does not support open option INDEX_COL\n",
      "  return ogr_read(\n",
      "C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\pyogrio\\raw.py:200: RuntimeWarning: driver GeoJSON does not support open option INDEX_COL\n",
      "  return ogr_read(\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "change_type_map = {'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,\n",
    "       'Mega Projects': 5}\n",
    "\n",
    "## Read csvs\n",
    "\n",
    "train_df = gpd.read_file('train.geojson', index_col=0)\n",
    "test_df = gpd.read_file('test.geojson', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-03T10:43:15.945167700Z",
     "start_time": "2026-02-03T10:43:14.531070800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\shapely\\measurement.py:50: RuntimeWarning: invalid value encountered in area\n",
      "  return lib.area(geometry, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "ename": "GEOSException",
     "evalue": "IllegalArgumentException: CGAlgorithmsDD::orientationIndex encountered NaN/Inf numbers",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mGEOSException\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 94\u001B[0m\n\u001B[0;32m     91\u001B[0m date_cols \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m5\u001B[39m)]\n\u001B[0;32m     92\u001B[0m status_cols \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchange_status_date\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m5\u001B[39m)]\n\u001B[1;32m---> 94\u001B[0m train_df \u001B[38;5;241m=\u001B[39m \u001B[43madd_geometry_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_df\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     95\u001B[0m test_df \u001B[38;5;241m=\u001B[39m add_geometry_features(test_df)\n\u001B[0;32m     98\u001B[0m train_df \u001B[38;5;241m=\u001B[39m add_max_gap_between_sets(train_df, date_cols, status_cols)\n",
      "Cell \u001B[1;32mIn[27], line 35\u001B[0m, in \u001B[0;36madd_geometry_features\u001B[1;34m(gdf, metric_epsg)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# print(gdf.geometry.length.isna().sum())\u001B[39;00m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m# print(gdf.geometry.area.isna().sum())\u001B[39;00m\n\u001B[0;32m     34\u001B[0m gdf_m \u001B[38;5;241m=\u001B[39m gdf\u001B[38;5;241m.\u001B[39mto_crs(epsg\u001B[38;5;241m=\u001B[39mmetric_epsg, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m---> 35\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mgdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgeometry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvex_hull\u001B[49m\u001B[38;5;241m.\u001B[39misna()\u001B[38;5;241m.\u001B[39msum())\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# print(gdf.geometry.area[gdf_m.geometry.area.isna()])\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# 2) calculs géométriques en mètres\u001B[39;00m\n\u001B[0;32m     38\u001B[0m gdf \u001B[38;5;241m=\u001B[39m gdf_m\u001B[38;5;241m.\u001B[39mcopy()\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\geopandas\\base.py:1199\u001B[0m, in \u001B[0;36mGeoPandasBase.convex_hull\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1155\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m   1156\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mconvex_hull\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1157\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return a ``GeoSeries`` of geometries representing the convex hull\u001B[39;00m\n\u001B[0;32m   1158\u001B[0m \u001B[38;5;124;03m    of each geometry.\u001B[39;00m\n\u001B[0;32m   1159\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1197\u001B[0m \n\u001B[0;32m   1198\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1199\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_delegate_property\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mconvex_hull\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\geopandas\\base.py:93\u001B[0m, in \u001B[0;36m_delegate_property\u001B[1;34m(op, this)\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_delegate_property\u001B[39m(op, this):\n\u001B[0;32m     91\u001B[0m     \u001B[38;5;66;03m# type: (str, GeoSeries) -> GeoSeries/Series\u001B[39;00m\n\u001B[0;32m     92\u001B[0m     a_this \u001B[38;5;241m=\u001B[39m GeometryArray(this\u001B[38;5;241m.\u001B[39mgeometry\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m---> 93\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(a_this, op)\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, GeometryArray):\n\u001B[0;32m     95\u001B[0m         \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgeoseries\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m GeoSeries\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\geopandas\\array.py:620\u001B[0m, in \u001B[0;36mGeometryArray.convex_hull\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    617\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mconvex_hull\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    619\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the convex hull of the geometries in this array.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m GeometryArray(\u001B[43mshapely\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvex_hull\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data\u001B[49m\u001B[43m)\u001B[49m, crs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcrs)\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\shapely\\decorators.py:88\u001B[0m, in \u001B[0;36mmultithreading_enabled.<locals>.wrapped\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m array_args:\n\u001B[0;32m     87\u001B[0m         arr\u001B[38;5;241m.\u001B[39mflags\u001B[38;5;241m.\u001B[39mwriteable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     90\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m arr, old_flag \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(array_args, old_flags):\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\shapely\\constructive.py:486\u001B[0m, in \u001B[0;36mconvex_hull\u001B[1;34m(geometry, **kwargs)\u001B[0m\n\u001B[0;32m    465\u001B[0m \u001B[38;5;129m@multithreading_enabled\u001B[39m\n\u001B[0;32m    466\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mconvex_hull\u001B[39m(geometry, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    467\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the minimum convex geometry that encloses an input geometry.\u001B[39;00m\n\u001B[0;32m    468\u001B[0m \n\u001B[0;32m    469\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    484\u001B[0m \n\u001B[0;32m    485\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 486\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvex_hull\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgeometry\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mGEOSException\u001B[0m: IllegalArgumentException: CGAlgorithmsDD::orientationIndex encountered NaN/Inf numbers"
     ]
    }
   ],
   "source": [
    "## Filtering column \"mail_type\"\n",
    "## Adding total construction time\n",
    "import pandas as pd\n",
    "\n",
    "PRE_CONSTRUCTION_STATUSES = {\n",
    "    \"Greenland\",\n",
    "    \"Land Cleared\",\n",
    "    \"Prior Construction\",\n",
    "    \"Excavation\",\n",
    "    \"Materials Dumped\",\n",
    "    \"Materials Introduced\",\n",
    "    \"Construction Started\",\n",
    "}\n",
    "\n",
    "POST_CONSTRUCTION_STATUSES = {\n",
    "    \"Construction Midway\",\n",
    "    \"Construction Done\",\n",
    "    \"Operational\",\n",
    "}\n",
    "\n",
    "\n",
    "def add_geometry_features(gdf, metric_epsg=6933):\n",
    "    \"\"\"\n",
    "    gdf: GeoDataFrame en EPSG:4326\n",
    "    Ajoute:\n",
    "      - polygon_area_m2\n",
    "      - polygon_perimeter_m\n",
    "      - compactness (sans unité)\n",
    "    \"\"\"\n",
    "    # 1) reprojection en CRS métrique (mètres)\n",
    "    print(gdf.geometry.area.isna().sum())\n",
    "    # print(gdf.geometry.length.isna().sum())\n",
    "    # print(gdf.geometry.area.isna().sum())\n",
    "    gdf_m = gdf.to_crs(epsg=metric_epsg, inplace=False)\n",
    "    print(gdf.geometry.convex_hull.isna().sum())\n",
    "    # print(gdf.geometry.area[gdf_m.geometry.area.isna()])\n",
    "    # 2) calculs géométriques en mètres\n",
    "    gdf = gdf_m.copy()\n",
    "    gdf[\"polygon_area_m2\"] = gdf.geometry.area\n",
    "    gdf[\"polygon_perimeter_m\"] = gdf.geometry.length\n",
    "\n",
    "    # 3) compacité = 4πA / P²\n",
    "    gdf[\"compactness\"] = (\n",
    "        4 * np.pi * gdf[\"polygon_area_m2\"] / (gdf[\"polygon_perimeter_m\"] ** 2)\n",
    "    )\n",
    "    # gdf.loc[gdf[\"polygon_perimeter_m\"] == 0, \"compactness\"] = np.nan\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def add_max_gap_between_sets(\n",
    "    df,\n",
    "    date_cols,     # ex: [\"date0\", ..., \"date4\"]\n",
    "    status_cols    # ex: [\"change_status_date0\", ..., \"change_status_date4\"]\n",
    "):\n",
    "    out = df.copy()\n",
    "\n",
    "    dates = out[date_cols].apply(pd.to_datetime, errors=\"coerce\", utc=True)\n",
    "    statuses = out[status_cols]\n",
    "\n",
    "    def row_max_gap(row_dates, row_statuses):\n",
    "        set1_dates = []\n",
    "        set2_dates = []\n",
    "\n",
    "        for d, s in zip(row_dates, row_statuses):\n",
    "            if pd.isna(d) or pd.isna(s):\n",
    "                continue\n",
    "            if s in PRE_CONSTRUCTION_STATUSES:\n",
    "                set1_dates.append(d)\n",
    "            elif s in POST_CONSTRUCTION_STATUSES:\n",
    "                set2_dates.append(d)\n",
    "\n",
    "        if not set1_dates or not set2_dates:\n",
    "            return 0.0\n",
    "\n",
    "        # max |t2 - t1|\n",
    "        max_gap = max(\n",
    "            abs((t2 - t1).total_seconds())\n",
    "            for t1 in set1_dates\n",
    "            for t2 in set2_dates\n",
    "        )\n",
    "\n",
    "        return max_gap / 86400.0  # en jours\n",
    "\n",
    "    out[\"pre_post_construction_time_gap_days\"] = [\n",
    "        row_max_gap(d, s)\n",
    "        for d, s in zip(dates.to_numpy(), statuses.to_numpy())\n",
    "    ]\n",
    "\n",
    "    return out\n",
    "\n",
    "date_cols = [f\"date{i}\" for i in range(5)]\n",
    "status_cols = [f\"change_status_date{i}\" for i in range(5)]\n",
    "\n",
    "train_df = add_geometry_features(train_df)\n",
    "test_df = add_geometry_features(test_df)\n",
    "\n",
    "\n",
    "train_df = add_max_gap_between_sets(train_df, date_cols, status_cols)\n",
    "test_df  = add_max_gap_between_sets(test_df, date_cols, status_cols)\n",
    "print(','.join(str(train_df[e].isna().sum()) for e in ['polygon_area_m2', 'polygon_perimeter_m', 'compactness']))\n",
    "print(train_df.crs)\n",
    "\n",
    "#\n",
    "# date_cols = [f'date{i}' for i in range(5)]\n",
    "# status_cols = [f'change_status_date{i}' for i in range(5)]\n",
    "#\n",
    "# def get_const_time(df):\n",
    "#     dt_cols = []\n",
    "#     for i, c in enumerate(date_cols):\n",
    "#         dtc = f\"dt_{i}\"\n",
    "#         df[dtc] = pd.to_datetime(df[c], errors=\"coerce\", utc=True)  # utc pour être stable\n",
    "#         dt_cols.append(dtc)\n",
    "#\n",
    "#     for i, c in enumerate(status_cols):\n",
    "#         df[f\"change_status_date{i}\"].apply(lambda x: status_cols[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T22:10:26.473806400Z",
     "start_time": "2026-02-02T22:10:26.358786700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296146, 4) (296146,) (120526, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train_x_d = np.asarray(train_df['date0'])\n",
    "feature_cols = [\n",
    "    \"pre_post_construction_time_gap_days\",\n",
    "    \"polygon_area_m2\",\n",
    "    \"polygon_perimeter_m\",\n",
    "    \"compactness\",\n",
    "]\n",
    "\n",
    "# X (numpy arrays)\n",
    "train_x = train_df[feature_cols].to_numpy(dtype=float)\n",
    "test_x  = test_df[feature_cols].to_numpy(dtype=float)\n",
    "\n",
    "# y (labels encodés)\n",
    "train_y = train_df[\"change_type\"].map(change_type_map).to_numpy()\n",
    "\n",
    "print(train_x.shape, train_y.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T23:24:28.819238200Z",
     "start_time": "2026-02-02T22:10:26.476804400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== AVANT =====\n",
      "F1 macro mean : 0.12368922830162718\n",
      "F1 macro std  : 0.00516401722936706\n",
      "\n",
      "===== APRÈS =====\n",
      "F1 macro mean : nan\n",
      "F1 macro std  : nan\n",
      "\n",
      "===== GAIN =====\n",
      "Gain absolu : nan\n",
      "Gain relatif (%) : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:490: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1336, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 613, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 547, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1484, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 910, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1336, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 447, in fit\n",
      "    X = self._validate_input(X, in_fit=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 374, in _validate_input\n",
      "    raise ve\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 355, in _validate_input\n",
      "    X = validate_data(\n",
      "        ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2902, in validate_data\n",
      "    out = check_array(X, input_name=\"X\", **check_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 133, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 182, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# =========================\n",
    "# PARAMÈTRES\n",
    "# =========================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# pipeline FIXE : Imputer -> Scaler -> SVC\n",
    "svc_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),  # gère NaN\n",
    "    (\"scaler\", StandardScaler()),                   # SVC a besoin de scaling\n",
    "    (\"model\", SVC(kernel=\"rbf\", C=1))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# FEATURES AVANT (baseline)\n",
    "# =========================\n",
    "baseline_features = [\n",
    "    \"polygon_area_m2\"   # <-- mets EXACTEMENT ce que tu utilisais avant\n",
    "]\n",
    "\n",
    "X_old = train_df[baseline_features].to_numpy(dtype=float)\n",
    "y = train_df[\"change_type\"].map(change_type_map).to_numpy()\n",
    "\n",
    "scores_old = cross_val_score(\n",
    "    svc_pipe, X_old, y,\n",
    "    cv=cv, scoring=\"f1_macro\", n_jobs=-1\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# FEATURES APRÈS (nouvelles)\n",
    "# =========================\n",
    "new_features = [\n",
    "    \"pre_post_construction_time_gap_days\",\n",
    "    \"polygon_area_m2\",\n",
    "    \"polygon_perimeter_m\",\n",
    "    \"compactness\",\n",
    "]\n",
    "\n",
    "X_new = train_df[new_features].to_numpy(dtype=float)\n",
    "\n",
    "scores_new = cross_val_score(\n",
    "    svc_pipe, X_new, y,\n",
    "    cv=cv, scoring=\"f1_macro\", n_jobs=-1\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# RÉSULTATS\n",
    "# =========================\n",
    "print(\"===== AVANT =====\")\n",
    "print(\"F1 macro mean :\", scores_old.mean())\n",
    "print(\"F1 macro std  :\", scores_old.std())\n",
    "\n",
    "print(\"\\n===== APRÈS =====\")\n",
    "print(\"F1 macro mean :\", scores_new.mean())\n",
    "print(\"F1 macro std  :\", scores_new.std())\n",
    "\n",
    "print(\"\\n===== GAIN =====\")\n",
    "print(\"Gain absolu :\", scores_new.mean() - scores_old.mean())\n",
    "print(\"Gain relatif (%) :\", (scores_new.mean() / scores_old.mean() - 1) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T23:24:46.496516300Z",
     "start_time": "2026-02-02T23:24:28.821575900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'multi_class' for estimator LogisticRegression(C=0.1, max_iter=5000). Valid parameters are: ['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'].",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31m_RemoteTraceback\u001B[0m                          Traceback (most recent call last)",
      "\u001B[1;31m_RemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 490, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 184, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 821, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 287, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 75, in _set_params\n    super().set_params(**params)\n  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 378, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"C:\\Users\\Ely Cheikh Abass\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 366, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'multi_class' for estimator LogisticRegression(C=0.1, max_iter=5000). Valid parameters are: ['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 115\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;66;03m# ---------- 4) GRIDSEARCH ----------\u001B[39;00m\n\u001B[0;32m    104\u001B[0m grid \u001B[38;5;241m=\u001B[39m GridSearchCV(\n\u001B[0;32m    105\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mpipe,\n\u001B[0;32m    106\u001B[0m     param_grid\u001B[38;5;241m=\u001B[39mparam_grid,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    112\u001B[0m     return_train_score\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    113\u001B[0m )\n\u001B[1;32m--> 115\u001B[0m \u001B[43mgrid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;66;03m# ---------- 5) RÉSULTATS ----------\u001B[39;00m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m===== BEST =====\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\base.py:1336\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1329\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1331\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1332\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1333\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1334\u001B[0m     )\n\u001B[0;32m   1335\u001B[0m ):\n\u001B[1;32m-> 1336\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1053\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m   1047\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m   1048\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m   1049\u001B[0m     )\n\u001B[0;32m   1051\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m-> 1053\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1055\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m   1056\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m   1057\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1612\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1610\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1611\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1612\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:999\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    991\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    992\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    993\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    994\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    995\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    996\u001B[0m         )\n\u001B[0;32m    997\u001B[0m     )\n\u001B[1;32m--> 999\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1000\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1001\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1002\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1003\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1004\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1005\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1006\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1007\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1008\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1009\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1010\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1011\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1012\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1013\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1014\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1015\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1017\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1018\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1019\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1020\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1021\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1022\u001B[0m     )\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:91\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     79\u001B[0m warning_filters \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     80\u001B[0m     filters_func() \u001B[38;5;28;01mif\u001B[39;00m filters_func \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mfilters\n\u001B[0;32m     81\u001B[0m )\n\u001B[0;32m     83\u001B[0m iterable_with_config_and_warning_filters \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     84\u001B[0m     (\n\u001B[0;32m     85\u001B[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     90\u001B[0m )\n\u001B[1;32m---> 91\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config_and_warning_filters\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   2066\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   2067\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   2068\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[0;32m   2069\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   2070\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 2072\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1679\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1681\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1682\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1684\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1685\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1686\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1687\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1688\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1784\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1778\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_retrieval():\n\u001B[0;32m   1779\u001B[0m     \u001B[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001B[39;00m\n\u001B[0;32m   1780\u001B[0m     \u001B[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001B[39;00m\n\u001B[0;32m   1781\u001B[0m     \u001B[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001B[39;00m\n\u001B[0;32m   1782\u001B[0m     \u001B[38;5;66;03m# worker traceback.\u001B[39;00m\n\u001B[0;32m   1783\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aborting:\n\u001B[1;32m-> 1784\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_error_fast\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1785\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m   1787\u001B[0m     nb_jobs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1859\u001B[0m, in \u001B[0;36mParallel._raise_error_fast\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1855\u001B[0m \u001B[38;5;66;03m# If this error job exists, immediately raise the error by\u001B[39;00m\n\u001B[0;32m   1856\u001B[0m \u001B[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001B[39;00m\n\u001B[0;32m   1857\u001B[0m \u001B[38;5;66;03m# called directly or if the generator is gc'ed.\u001B[39;00m\n\u001B[0;32m   1858\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m error_job \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1859\u001B[0m     \u001B[43merror_job\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_result\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\joblib\\parallel.py:758\u001B[0m, in \u001B[0;36mBatchCompletionCallBack.get_result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    752\u001B[0m backend \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparallel\u001B[38;5;241m.\u001B[39m_backend\n\u001B[0;32m    754\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend\u001B[38;5;241m.\u001B[39msupports_retrieve_callback:\n\u001B[0;32m    755\u001B[0m     \u001B[38;5;66;03m# We assume that the result has already been retrieved by the\u001B[39;00m\n\u001B[0;32m    756\u001B[0m     \u001B[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001B[39;00m\n\u001B[0;32m    757\u001B[0m     \u001B[38;5;66;03m# be returned.\u001B[39;00m\n\u001B[1;32m--> 758\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_return_or_raise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    760\u001B[0m \u001B[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001B[39;00m\n\u001B[0;32m    761\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\Cours\\Kaggle_ML\\area_classification\\.venv\\Lib\\site-packages\\joblib\\parallel.py:773\u001B[0m, in \u001B[0;36mBatchCompletionCallBack._return_or_raise\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    771\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    772\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m TASK_ERROR:\n\u001B[1;32m--> 773\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n\u001B[0;32m    774\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n\u001B[0;32m    775\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[1;31mValueError\u001B[0m: Invalid parameter 'multi_class' for estimator LogisticRegression(C=0.1, max_iter=5000). Valid parameters are: ['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start']."
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# GRIDSEARCH \"PROPRE & FORT\"\n",
    "# - gère les NaN (imputer)\n",
    "# - compare plusieurs algos\n",
    "# - optimise F1 macro (Kaggle metric)\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ---------- 1) CHOISIS TES FEATURES ----------\n",
    "feature_cols = [\n",
    "    \"pre_post_construction_time_gap_days\",\n",
    "    \"polygon_area_m2\",\n",
    "    \"polygon_perimeter_m\",\n",
    "    \"compactness\",\n",
    "]\n",
    "\n",
    "X = train_df[feature_cols].to_numpy(dtype=float)\n",
    "y = train_df[\"change_type\"].map(change_type_map).to_numpy()\n",
    "\n",
    "# ---------- 2) CV + PIPELINE BASE ----------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),  # gère NaN pour TOUS les modèles\n",
    "    (\"scaler\", StandardScaler()),                   # utile pour SVC/LogReg, neutre si passthrough\n",
    "    (\"model\", LogisticRegression())                 # placeholder, remplacé par GridSearch\n",
    "])\n",
    "\n",
    "# ---------- 3) GRILLES (une par modèle) ----------\n",
    "param_grid = [\n",
    "    # ---- SVC RBF (souvent très bon si features OK) ----\n",
    "    {\n",
    "        \"scaler\": [StandardScaler()],\n",
    "        \"model\": [SVC(kernel=\"rbf\")],\n",
    "        \"model__C\": [0.3, 1, 3, 10],\n",
    "        \"model__gamma\": [\"scale\", \"auto\"],\n",
    "        \"model__class_weight\": [None, \"balanced\"],\n",
    "    },\n",
    "\n",
    "    # ---- Logistic Regression (baseline solide) ----\n",
    "    {\n",
    "        \"scaler\": [StandardScaler()],\n",
    "        \"model\": [LogisticRegression(max_iter=5000, n_jobs=None)],\n",
    "        \"model__C\": [0.1, 1, 10],\n",
    "        \"model__class_weight\": [None, \"balanced\"],\n",
    "        \"model__solver\": [\"lbfgs\"],\n",
    "        \"model__multi_class\": [\"auto\"],\n",
    "    },\n",
    "\n",
    "    # ---- RandomForest (robuste, pas sensible au scaling) ----\n",
    "    {\n",
    "        \"scaler\": [\"passthrough\"],\n",
    "        \"model\": [RandomForestClassifier(random_state=42, n_jobs=1)],\n",
    "        \"model__n_estimators\": [400, 800],\n",
    "        \"model__max_depth\": [None, 12, 24],\n",
    "        \"model__min_samples_split\": [2, 8],\n",
    "        \"model__min_samples_leaf\": [1, 3],\n",
    "        \"model__class_weight\": [None, \"balanced_subsample\"],\n",
    "    },\n",
    "\n",
    "    # ---- ExtraTrees (souvent encore meilleur que RF) ----\n",
    "    {\n",
    "        \"scaler\": [\"passthrough\"],\n",
    "        \"model\": [ExtraTreesClassifier(random_state=42, n_jobs=1)],\n",
    "        \"model__n_estimators\": [600, 1200],\n",
    "        \"model__max_depth\": [None, 18, 30],\n",
    "        \"model__min_samples_split\": [2, 8],\n",
    "        \"model__min_samples_leaf\": [1, 3],\n",
    "        \"model__class_weight\": [None, \"balanced\"],\n",
    "    },\n",
    "\n",
    "    # ---- AdaBoost (à tester, parfois très bon, parfois sensible au bruit) ----\n",
    "    {\n",
    "        \"scaler\": [\"passthrough\"],\n",
    "        \"model\": [AdaBoostClassifier(\n",
    "            estimator=DecisionTreeClassifier(max_depth=2, random_state=42),\n",
    "            random_state=42\n",
    "        )],\n",
    "        \"model__n_estimators\": [200, 400],\n",
    "        \"model__learning_rate\": [0.05, 0.2, 0.6],\n",
    "    },\n",
    "\n",
    "    # ---- HistGradientBoosting (très fort en tabulaire; gère bien) ----\n",
    "    {\n",
    "        \"scaler\": [\"passthrough\"],\n",
    "        \"model\": [HistGradientBoostingClassifier(random_state=42)],\n",
    "        \"model__learning_rate\": [0.03, 0.1],\n",
    "        \"model__max_depth\": [None, 6, 12],\n",
    "        \"model__max_leaf_nodes\": [31, 63, 127],\n",
    "        \"model__min_samples_leaf\": [10, 30],\n",
    "    },\n",
    "]\n",
    "\n",
    "# ---------- 4) GRIDSEARCH ----------\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "# ---------- 5) RÉSULTATS ----------\n",
    "print(\"\\n===== BEST =====\")\n",
    "print(\"best f1_macro:\", grid.best_score_)\n",
    "print(\"best params:\", grid.best_params_)\n",
    "print(\"best model:\", grid.best_estimator_)\n",
    "\n",
    "# ---------- 6) BEST MODEL prêt pour train/test ----------\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# (option) fit sur tout le train (déjà fait par refit=True)\n",
    "# best_model.fit(X, y)\n",
    "\n",
    "# (option) prédire test (assure-toi que test_df a les mêmes features + mêmes noms)\n",
    "# X_test = test_df[feature_cols].to_numpy(dtype=float)\n",
    "# y_test_pred = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Predict and create csv prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_y = grid.predict(test_x)\n",
    "print(f\"{accuracy_score(train_y, pred_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## Save results to submission file\n",
    "pred_df = pd.DataFrame(pred_y, columns=['change_type'])\n",
    "pred_df.to_csv(\"knn_sample_submission.csv\", index=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
